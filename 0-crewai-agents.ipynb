{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b5a200bd",
   "metadata": {},
   "source": [
    "# 0-intro-crewai-agents\n",
    "> An opinionated yet intuitive framework for building fast, scalable agents\n",
    "\n",
    "We need to do a few pip installs to get the environment setup\n",
    "\n",
    "```bash\n",
    "python3 -m venv crewai-venv\n",
    "source crewai-venv/bin/activate\n",
    "pip install ipykernel \"crewai[tools]\" python-dotenv langchain-community pymupdf pypdf2\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5055d37",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "# Import the necessary libraries\n",
    "from crewai import Agent, Crew, Task, Process\n",
    "from crewai_tools import VisionTool"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97850ccd",
   "metadata": {},
   "source": [
    "## Theory of CrewAI\n",
    "\n",
    "![Basic CrewAI Architecture](https://mintlify.s3.us-west-1.amazonaws.com/crewai/crews.png)\n",
    "\n",
    "* A **Crew** is composed of one or more **agents**. The crew has one or more **tasks** that it is required to carry out.\n",
    "* A **Task** is an assignment to be completed. The crew is responsible for carrying out the task. A task can be specifically associated with one agent, but this is not required.\n",
    "* An **Agent** has one or more **Tools** at its disposal.\n",
    "\n",
    "Because this is an agentic framework, the collective crew has memory (several different types). The collective crew can also have planning enabled. Individual agents can also have memory."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e77667df",
   "metadata": {},
   "source": [
    "## Creating our first Crew AI Crew\n",
    "\n",
    "Let's make a Crew whose purpose is to extract text from an image."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98bf73d2",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "## Instantiate the tools\n",
    "We'll use the [VisionTool](https://docs.crewai.com/tools/visiontool) to extract text from an image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4449ae6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the VisionTool\n",
    "vision_tool = VisionTool()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "068d5e0d",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "## Define the Agent\n",
    "Visit https://docs.crewai.com/concepts/agents#direct-code-definition to learn more. Below are the full options for the agent.\n",
    "This basically resolves to determining the role of the agent, specifically:\n",
    "* The role title\n",
    "* The goal of the agent\n",
    "* The backstory of the agent\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "779bf52e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an agent with all available parameters\n",
    "ocr_reader = Agent(\n",
    "    role=\"Handwritten Text Transcriber\",\n",
    "    goal=\"To create computer-readable text from an image of a handwritten documents with high fidelity for formatting, content, and structure\",\n",
    "    backstory=\"You are an OCR expert who can extract text from an image. You take great pride in your work and want to make sure that the\"+\n",
    "    \"visual formatting of the document is preserved in the output. After you do your transcript, you check you work to make sure that the \"+\n",
    "    \"written text makes sense.\",\n",
    "    llm=\"gpt-4o-mini\",  # Default: OPENAI_MODEL_NAME or \"gpt-4\"\n",
    "    function_calling_llm=None,  # Optional: Separate LLM for tool calling\n",
    "    memory=True,  # Default: True\n",
    "    verbose=True,  # *******Default: False\n",
    "    allow_delegation=False,  # Default: False\n",
    "    max_iter=20,  # Default: 20 iterations\n",
    "    max_rpm=None,  # Optional: Rate limit for API calls\n",
    "    max_execution_time=None,  # Optional: Maximum execution time in seconds\n",
    "    max_retry_limit=2,  # Default: 2 retries on error\n",
    "    allow_code_execution=False,  # Default: False\n",
    "    code_execution_mode=\"safe\",  # Default: \"safe\" (options: \"safe\", \"unsafe\")\n",
    "    respect_context_window=True,  # Default: True\n",
    "    use_system_prompt=True,  # Default: True\n",
    "    tools=[vision_tool],  # *******Optional: List of tools\n",
    "    knowledge_sources=None,  # Optional: List of knowledge sources\n",
    "    embedder=None,  # Optional: Custom embedder configuration\n",
    "    system_template=None,  # Optional: Custom system prompt template\n",
    "    prompt_template=None,  # Optional: Custom prompt template\n",
    "    response_template=None,  # Optional: Custom response template\n",
    "    step_callback=None,  # Optional: Callback function for monitoring\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3eca900",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "## Define the task\n",
    "Learn more here: [Task](https://docs.crewai.com/concepts/tasks)\n",
    "\n",
    "The purpose of a task is to define the assignment that an agent will complete. Minimally, you need a description of the task to be completed, the expected output, and the agent that is responsible to complete the task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "616ea67e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a task\n",
    "main_task = Task(\n",
    "    description=\"Convert the image of the handwritten lecture notes from this file {handwritten_image_file} into its digital text form so that I can post them for my students to read.\",\n",
    "    expected_output=\"A markdown formatted document with the transcribed lecture notes, making sure not to include ```markdown formatting in the output.\",\n",
    "    agent=ocr_reader,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11f391d9",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "## Define the Crew"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6a3d0101",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a crew\n",
    "crew = Crew(\n",
    "    agents=[ocr_reader],\n",
    "    tasks=[main_task],\n",
    "    process = Process.sequential,\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e941dab",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "## Run the Crew"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "986746e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the crew\n",
    "png_image_file = 'Old-Class-Notes.png'\n",
    "result = crew.kickoff({\"handwritten_image_file\": png_image_file})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c13a486",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "## Print the result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff3cd59f",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# Print the result\n",
    "print(result)"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "kernelspec": {
   "display_name": "crewai-venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
